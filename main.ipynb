{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou3sPZ9kTle7",
        "outputId": "237fdb7a-7a3e-419c-dd79-c11c411a5708"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x870i4huUocY"
      },
      "source": [
        "## **Dual Contradistinctive Generative Autoencoder - CVPR 2021** \n",
        "---\n",
        "* **Authors:** *Gaurav Parmar, Dacheng Li, Kwonjoon Lee, Zhuowen Tu*\n",
        "* **Link:** https://arxiv.org/abs/2011.10063\n",
        "* **Official Implementation:** https://github.com/mlpc-ucsd/DC-VAE\n",
        "\n",
        "#### **Project Group Members**\n",
        "* Aybora Köksal aybora@metu.edu.tr\n",
        "* Halil Çağrı Bilgi cagri.bilgi@metu.edu.tr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3A8YiCjXMh3"
      },
      "source": [
        "# **Paper Summary**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uCG2oHZX4h8"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aR8wJ7cMUBFJ"
      },
      "outputs": [],
      "source": [
        "from lib import *\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path as osp\n",
        "import os \n",
        "\n",
        "import sacred\n",
        "from sacred import Experiment\n",
        "from sacred.observers import FileStorageObserver\n",
        "from sacred import SETTINGS\n",
        "SETTINGS.CONFIG.READ_ONLY_CONFIG=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PraP2wKdZKDV"
      },
      "source": [
        "# Hyperparameters & Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZAUec-SyZT3K"
      },
      "outputs": [],
      "source": [
        "configs = {\n",
        "    'model_params' : {\n",
        "        'decoder': {\n",
        "            'latent_dim' : 128,\n",
        "            'channel_dim' : 256\n",
        "        },\n",
        "\n",
        "        'encoder' : {\n",
        "            'ch_in' : 3,\n",
        "            'hid_ch': 128,\n",
        "            'z_dim' : 128\n",
        "        },\n",
        "\n",
        "        'discriminator' : {\n",
        "            'ch_in' : 3, \n",
        "            'hid_ch': 128,\n",
        "            'cont_dim' : 16\n",
        "        }\n",
        "    },\n",
        "\n",
        "    'hparams' : {\n",
        "        'epochs' : 800,\n",
        "        'train_batch_size' : 64, \n",
        "        'test_batch_size' : 64,\n",
        "        'lr' : 0.0002,\n",
        "        'disp_freq' : 20,\n",
        "        'gen_train_freq' : 5,\n",
        "        'checkpoint': 500,\n",
        "        'beta1' : 0.0,\n",
        "        'beta2' : 0.9,\n",
        "        'device' : torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TmVB-8jIdKEP"
      },
      "outputs": [],
      "source": [
        "model_params = configs[\"model_params\"]\n",
        "hparams = configs[\"hparams\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JraHwBsWdSz2"
      },
      "source": [
        "## Model & Optimizer & Loss Function Initializations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "HYLXOEu-dSMz",
        "outputId": "d61843ac-08cb-421a-f79c-92f6a7310fce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hcagri/Documents/METU-Master/Term II/CENG 796/project/Dual-Contradistinctive-Generative-Autoencoder/lib/utils.py:24: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight.data, 1.)\n"
          ]
        }
      ],
      "source": [
        "model = Model(model_params)\n",
        "model.apply(weights_init)\n",
        "\n",
        "enc_optim = torch.optim.Adam(model.encoder.parameters(), lr = hparams['lr'], betas = (hparams['beta1'], hparams['beta2']))\n",
        "dec_optim = torch.optim.Adam(model.decoder.parameters(), lr = hparams['lr'], betas = (hparams['beta1'], hparams['beta2']))\n",
        "disc_optim = torch.optim.Adam(model.discriminator.parameters(), lr = hparams['lr'], betas = (hparams['beta1'], hparams['beta2']))\n",
        "\n",
        "gan_criterion = torch.nn.BCEWithLogitsLoss()\n",
        "# contrastive_loss is imported from lib/loss.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzoRiR-Xc7eX"
      },
      "source": [
        "## Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xX5O_Pihc6sI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(\n",
        "    torchvision.datasets.CIFAR10(\n",
        "        './data', \n",
        "        train = True,\n",
        "        download = True, \n",
        "        transform = transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize(\n",
        "                                (0.5, 0.5, 0.5), \n",
        "                                (0.5, 0.5, 0.5)),\n",
        "                        ])\n",
        "        ),\n",
        "    batch_size=hparams['train_batch_size'], \n",
        "    shuffle=True, \n",
        "    drop_last=True\n",
        "    )\n",
        "\n",
        "test_loader = DataLoader(torchvision.datasets.CIFAR10(\n",
        "    './data', \n",
        "    train = False, transform = transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize(\n",
        "                                (0.5, 0.5, 0.5), \n",
        "                                (0.5, 0.5, 0.5)),\n",
        "                        ])\n",
        "    ),\n",
        "    batch_size=hparams['test_batch_size'], \n",
        "    shuffle=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loop and Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeLBa1w9Zp3H"
      },
      "outputs": [],
      "source": [
        "def train_in_notebook(model_params, hparams, model, gan_criterion, enc_optim ,dec_optim, disc_optim, _run, device = torch.device(\"cpu\")):\n",
        "    \n",
        "    model.to(device)\n",
        "\n",
        "    torch.manual_seed(123)\n",
        "\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.manual_seed(123)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    ####### LOG #######\n",
        "    disc_train_loss = 0\n",
        "    gen_train_loss = 0\n",
        "    cont_train_loss = 0\n",
        "\n",
        "    mean_generator_loss = 0\n",
        "    mean_discriminator_loss = 0\n",
        "    mean_contrastive_loss = 0\n",
        "\n",
        "    _run.info[\"gen_loss_train\"] = list()\n",
        "    _run.info[\"disc_loss_train\"] = list()\n",
        "    _run.info[\"cont_loss_train\"] = list()\n",
        "    _run.info[\"fid\"] = list()\n",
        "    ###################\n",
        "\n",
        "    disp_freq = hparams['disp_freq']\n",
        "    step = 1\n",
        "\n",
        "    for epoch in range(1,hparams['epochs']+1):\n",
        "        \n",
        "        iterator = tqdm(train_loader, leave=True)\n",
        "        iterator.set_description_str(f\"Epoch: {epoch}\")\n",
        "        batch_id = 0\n",
        "        for point_batch, _ in iterator: \n",
        "\n",
        "            model.train()\n",
        "            \n",
        "            batch_id += 1\n",
        "            \n",
        "            model.train()\n",
        "            model.device = device\n",
        "\n",
        "            #### Real Data\n",
        "            real_data = point_batch.to(device) \n",
        "\n",
        "            '''----------------         Discriminator Update         ----------------'''\n",
        "            disc_optim.zero_grad()\n",
        "            \n",
        "            fake_data = model.gen_from_noise(size=(real_data.size(0), model_params['decoder']['latent_dim']))\n",
        "            z_latent, rec_data = model(real_data)\n",
        "\n",
        "            disc_fake_pred, _ = model.discriminator(fake_data)\n",
        "            disc_fake_loss = gan_criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
        "\n",
        "            disc_rec_pred, _ = model.discriminator(rec_data)\n",
        "            disc_rec_loss = gan_criterion(disc_rec_pred, torch.zeros_like(disc_rec_pred))\n",
        "\n",
        "            disc_real_pred, _ = model.discriminator(real_data)\n",
        "            disc_real_loss = gan_criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
        "\n",
        "            gan_objective = disc_real_loss + (disc_rec_loss + disc_fake_loss)*0.5 \n",
        "            gan_objective.backward(retain_graph = True)\n",
        "            disc_optim.step()\n",
        "\n",
        "            ### Log\n",
        "            _run.info[\"disc_loss_train\"].append(gan_objective.item())\n",
        "            disc_train_loss = gan_objective.item()\n",
        "            mean_discriminator_loss += gan_objective.item()\n",
        "            ########\n",
        "\n",
        "            '''----------------         Generator Update         ----------------'''\n",
        "            if step % hparams['gen_train_freq'] == 0:\n",
        "\n",
        "                # KLD loss term missing !!!!!\n",
        "                enc_optim.zero_grad()\n",
        "                dec_optim.zero_grad()\n",
        "                \n",
        "                fake_data = model.gen_from_noise(size=(2*real_data.size(0), model_params['decoder']['latent_dim']))\n",
        "                z_latent, rec_data = model(real_data)\n",
        "\n",
        "                gen_fake_pred, _ = model.discriminator(fake_data)\n",
        "                gen_fake_loss = gan_criterion(gen_fake_pred, torch.ones_like(gen_fake_pred))\n",
        "\n",
        "                gen_rec_pred, _ = model.discriminator(rec_data)\n",
        "                gen_rec_loss = gan_criterion(gen_rec_pred, torch.ones_like(gen_rec_pred))\n",
        "\n",
        "                gan_objective =  gen_rec_loss + gen_fake_loss \n",
        "\n",
        "                gan_objective.backward(retain_graph = True)\n",
        "                enc_optim.step()\n",
        "                dec_optim.step()\n",
        "\n",
        "                ### Log\n",
        "                _run.info[\"gen_loss_train\"].append(gan_objective.item())\n",
        "                gen_train_loss = gan_objective.item()\n",
        "                mean_generator_loss += gan_objective.item() \n",
        "                ########\n",
        "            \n",
        "                '''----------------         Contrastive Update         ----------------'''\n",
        "\n",
        "                enc_optim.zero_grad()\n",
        "                dec_optim.zero_grad()\n",
        "                disc_optim.zero_grad()\n",
        "\n",
        "                z_latent, rec_data = model(real_data)\n",
        "\n",
        "                _, rec_contrastive = model.discriminator(rec_data)\n",
        "                _, real_contrastive = model.discriminator(real_data)\n",
        "\n",
        "                cont_loss = contrastive_loss(z_latent, real_contrastive, rec_contrastive)\n",
        "\n",
        "                cont_loss.backward()\n",
        "                \n",
        "                disc_optim.step()\n",
        "                enc_optim.step()\n",
        "                dec_optim.step()\n",
        "\n",
        "                ### Log\n",
        "                _run.info[\"cont_loss_train\"].append(cont_loss.item())\n",
        "                cont_train_loss = cont_loss.item()\n",
        "                mean_contrastive_loss += cont_loss.item() \n",
        "                ########\n",
        "            \n",
        "            # Visualize the generated & reconstructed images\n",
        "            if step % disp_freq == 0:\n",
        "                gen_images = model.gen_from_noise(size = (25, model_params['decoder']['latent_dim']))\n",
        "                t_data, _ = iter(test_loader).next()\n",
        "                t_data = t_data.to(device)\n",
        "                _ , rec_t_data = model(t_data)\n",
        "                show_img(gen_images, step, num_images=25, size=(3, 32, 32), img_save_path=osp.join(_run.experiment_info['base_dir'], 'runs', _run._id, 'results'), show=False)\n",
        "                show_img_rec(t_data, rec_t_data, step, num_images=15, size=(3, 32, 32), img_save_path=osp.join(_run.experiment_info['base_dir'], 'runs', _run._id, 'results'), show=False)\n",
        "            \n",
        "            step += 1\n",
        "\n",
        "            iterator.set_postfix_str(\n",
        "                f\"Disc Loss: {disc_train_loss:.4f}, Gen Loss: {gen_train_loss:.4f}, Cont Loss: {cont_train_loss:.4f}, Step: {step} \" )\n",
        "            \n",
        "            '''----------------         Save Model         ----------------'''\n",
        "            if step % hparams['checkpoint'] == 0:\n",
        "                c_name = f\"checkpoint_{step}.pt\"\n",
        "                checkpoint_path = osp.join(_run.experiment_info['base_dir'], 'runs', _run._id, \"checkpoints\", c_name)\n",
        "                torch.save(model.state_dict(), checkpoint_path)\n",
        "        \n",
        "        # Calculate FID score at the end of each Epoch\n",
        "        fid_samp = eval(model, model_params['decoder']['latent_dim'], hparams['test_batch_size'], device)\n",
        "        print(f\"Epoch: {epoch}| sampling fid: {fid_samp}\")\n",
        "        _run.info[\"fid\"].append(fid_samp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Experiment and Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dirname = os.path.dirname(os.path.realpath(\"__file__\"))\n",
        "\n",
        "experiment_dir = os.path.join(dirname, 'runs')\n",
        "\n",
        "ex = Experiment(\"ceng796\")\n",
        "ex.observers.append(FileStorageObserver(experiment_dir))\n",
        "ex.add_config(configs)\n",
        "\n",
        "@ex.automain\n",
        "def main(_config, _run):\n",
        "    sacred.commands.print_config(_run)\n",
        "    \n",
        "    os.makedirs(os.path.join(experiment_dir, _run._id, \"checkpoints\"))\n",
        "    os.makedirs(os.path.join(experiment_dir, _run._id, \"results\"))\n",
        "    \n",
        "    train_in_notebook(model_params, hparams, model, gan_criterion, enc_optim ,dec_optim, disc_optim, _run, device = hparams['device'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "main.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "7b8e6e8f045ddc223995b2b3bc0209434bb9d9ca4413b5920847e9ff5a76183d"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('torch_pip')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
